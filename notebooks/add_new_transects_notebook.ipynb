{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# External Imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Convert the New Geojson File to CRS 4326\n",
    "1. Enter the name of the geojson file into the variable **geojson_file**\n",
    "- Make sure to put this geojson file in the main coastseg directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the name of the geojson file\n",
    "geojson_file = \"\"\n",
    "# Example: geojson_file = \"usa_southeast_transects_DE.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Move the geojson file into the main coastseg directory\n",
    "- Manually drop the file into the coastseg directory\n",
    "- After you moved the file there run the following block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.abspath(os.path.dirname(os.getcwd()))+os.sep+geojson_file \n",
    "print(f\"File does not exist at: {filepath}\") if not os.path.exists(filepath) else print(f\"File exists at: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert geojson file to crs 4326\n",
    "- Run the following code block to convert to epsg 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the geojson file into a geodataframe\n",
    "gdf = gpd.read_file(filepath)\n",
    "# convert to new crs\n",
    "gdf = gdf.to_crs(\"epsg:4326\")\n",
    "# overwrites the original file\n",
    "gdf.to_file(filepath,driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the geodataframe for the transects to see if it looks alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any z-axis geometeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_z_axis(geodf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"If the geodataframe has z coordinates in any rows, the z coordinates are dropped.\n",
    "    Otherwise the original geodataframe is returned.\n",
    "\n",
    "    Additionally any multi part geometeries will be exploded into single geometeries.\n",
    "    eg. MutliLineStrings will be converted into LineStrings.\n",
    "    Args:\n",
    "        geodf (gpd.GeoDataFrame): geodataframe to check for z-axis\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: original dataframe if there is no z axis. If a z axis is found\n",
    "        a new geodataframe is returned with z axis dropped.\n",
    "    \"\"\"\n",
    "    if geodf.empty:\n",
    "        print(f\"Empty geodataframe has no z-axis\")\n",
    "        return geodf\n",
    "\n",
    "    # if any row has a z coordinate then remove the z_coordinate\n",
    "    if geodf[\"geometry\"].has_z.any():\n",
    "\n",
    "        def remove_z_from_row(row):\n",
    "            if row.geometry.has_z:\n",
    "                row.geometry = shapely.ops.transform(\n",
    "                    lambda x, y, z=None: (x, y), row.geometry\n",
    "                )\n",
    "                return row\n",
    "            else:\n",
    "                return row\n",
    "\n",
    "        # Use explode to break multilinestrings in linestrings\n",
    "        feature_exploded = geodf.explode(ignore_index=True)\n",
    "        # For each linestring portion of feature convert to lat,lon tuples\n",
    "        no_z_gdf = feature_exploded.apply(remove_z_from_row, axis=1)\n",
    "        return no_z_gdf\n",
    "    else:\n",
    "        return geodf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = remove_z_axis(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Create an ID column and drop unneeded columns\n",
    "Transects in coastseg are identified by a unique id in the column 'id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols_except_id_slope_geom(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # Ensure column names are all lowercase\n",
    "    gdf.columns = [col.lower() for col in gdf.columns]\n",
    "\n",
    "    # Identify columns to drop\n",
    "    cols_to_drop = set(gdf.columns) - set(['geometry'])\n",
    "    if 'id' in gdf.columns:\n",
    "        cols_to_drop -= set(['id'])\n",
    "    if 'slope' in gdf.columns:\n",
    "        cols_to_drop -= set(['slope'])\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    gdf.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    # Ensure 'id' and 'slope' columns exist in the GeoDataFrame\n",
    "    if 'id' not in gdf.columns:\n",
    "        gdf['id'] = None\n",
    "    if 'slope' not in gdf.columns:\n",
    "        gdf['slope'] = None\n",
    "\n",
    "    # Rearrange columns\n",
    "    cols = ['id', 'slope', 'geometry']\n",
    "    gdf = gdf[[col for col in cols if col in gdf.columns]]\n",
    "\n",
    "    # Drop the slope column if it's empty\n",
    "    if gdf['slope'].isna().all():\n",
    "        gdf.drop('slope', axis=1, inplace=True)\n",
    "\n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unique ids for each transects\n",
    "Only run this code if the id for each transect is not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf['id'] = [i for i, _ in enumerate(gdf.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop any columns that won't be used\n",
    "Always run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'id' not in gdf.columns:\n",
    "    gdf['id'] = [i for i, _ in enumerate(gdf.index)]\n",
    "    \n",
    "gdf = drop_cols_except_id_slope_geom(gdf)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a new Bounding Box for all the transects\n",
    "1. Move the new geojson file into the transects directory\n",
    "- Run the following code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modified geodataframe to file\n",
    "gdf.to_file(filepath,driver=\"GeoJSON\")\n",
    "# full path to transects directory which contains all the transect geojson files\n",
    "transects_folder=os.path.join( os.path.abspath(os.path.dirname(os.getcwd())),\"src\",\"coastseg\",\"transects\")\n",
    "destination = os.path.join(transects_folder,geojson_file)\n",
    "# move the new geojson file to the transects directory\n",
    "shutil.move(filepath, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make a list of the full paths to all the transect geojson files in the transects directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transects=glob.glob(transects_folder+os.sep+\"*.geojson\")\n",
    "transects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make a list of all the transect geojson filenames in the transects directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_layer_names=[os.path.basename(transect) for transect in transects]\n",
    "transect_layer_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a list of the total bounds for each transect geojson file\n",
    "- This might take awhile because it has to open and close each geojson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transects_total_bounds=[gpd.read_file(transect_file).total_bounds for transect_file in transects]\n",
    "transects_total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a dataframe with the total bounds and filename of each transects file\n",
    "- Each transect's bounding box is used to determine if any of its transects could intersect the ROI/bbox drawn by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(transects_total_bounds,columns=['minx', 'miny', 'maxx', 'maxy'])\n",
    "df['filename'] = transect_layer_names\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save the dataframe to a csv file \n",
    "- Save the new CSV file to the bounding_boxes directory\n",
    "- This bounding box is used to determine if any of the transects could intersect the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"transects_bounding_boxes.csv\"\n",
    "bounding_box_path = os.path.join(os.path.abspath(os.path.dirname(os.getcwd())),\"src\",\"coastseg\",\"bounding_boxes\")\n",
    "csv_path = transect_folder=os.path.join(bounding_box_path,csv_file)\n",
    "df.to_csv(csv_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 (Optional): Open the csv file to verify it looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transects_df=pd.read_csv(csv_path)\n",
    "transects_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d097efbdf24db87a2507c17c632c6d564e7aff5ba5cfc04e62a44a8b3d6a20a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
